%This file will document the actual coding practices that we are using, the data structures we are creating, and links to ideas or research %that we are using to build our program.

\documentclass[a4paper,11pt]{article}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage[top=.6in, bottom=.8in, left=.8in, right=.8in]{geometry}
\title{3D Localization Program \\ Official Code Documentation}
\author{ \\[6.5in]  John Allard, Alex Rich \\ 2014 Summer Computer Science REU, Harvey Mudd College}
\date{July 10th, 2014}


\begin{document}

% Title Page %
  \maketitle
  
  \newpage

% Table of Contents (autogen)
    \tableofcontents
    \newpage
    
% Introduction to the program, abstract, keep it short %
    \begin{abstract}
    This is the official documentation for a series of interconnected programs written at Harvey Mudd during the summer of 2014 by John Allard and Alex Rich. The purpose of these programs is to successfully localize an actor in an environment using a preloaded 3D map, precomputed computer-vision related feature data, and a live image feed from an actor in the environment. The program starts with a large amount of guesses as to where the actor could be, and uses particle filtering to converge the particles upon the correct location in the environment. Read the research paper associated with this project for more information on the mathematics and other technicalities behind Monte Carlo Localization.
    \end{abstract}

% === Section 1, Introduction === %
    \section{Introduction}
    Accomplishing the task of successfully locating an actor in an environment using CV-derived features and a 3D model requires many individual steps. The success of the localization attempt depends strongly on the computation and data storage that is done before any attempt is made. With this in mind, we dicided to subdivide the task of localizing an actor into three separate programs that must be run individually. Two of them are done before the localization attempt and are only needed to be ran once for each map that an actor is attempting to localize itself in. The 3rd program is the actual localization code that matches features to figure out where the actor is in the given map.

        % == Subsection 1.1, prelocalization == %
        \subsection{Pre-Localization}

        \begin{enumerate}
        \item PerspectiveGenerator
            \begin{enumerate}
            \item Takes a 3d model and a list of points within that model.
            \item Renders images from every point listed and saves them in a directory for feature processing. Works with .obj files. TODO Figure out if it works with .3ds and .dae files. TODO
            \end{enumerate}
        \item DatabaseGenerator
            \begin{enumerate}
            \item Generates a database of computer-vision related feature data.
            \item This feature data can range from greyscale image, black and white image, SURF/SIFT/ORB feature data and descriptors, or even images that are contrast tuned.
            \item This program does the majority of the work and is the reason this Localization program can run efficiently in real time, it computes mounds of data and writes it all to file for future use.
            \end{enumerate}
        \end{enumerate}
  
        \subsection{During Localization}
        \begin{enumerate}
        \item 3DLocalization TODO Think of a better name TODO
            \begin{enumerate}
            \item This program handles the live process of communicating with the robot, generating particles, weighing particles, and pursuing the general goal of localization.
            \item This is also the most important program and will have the most effort put into it as far as code documentation and good coding practices go.
            \item There are too many things to talk about to go into detail here, go to the section for this program later on in this document.
            \end{enumerate}
        \end{enumerate}
        \newpage

%==== Section 2, Perspective Generator === %
    \section{Perspective Generator}

        \subsection{Overview}
        \begin{enumerate}
        \item General Purpose - The general purpose of this program is to convert a 3D model into a processable library of images that are rendered from different points in the model. This serves the purpose of allowing us to use existing 2D-Image feature detection algorithms (like Sped-Up Robust Feature Detection, or Scale Invariant Feature Detection) to match a 2D image feed from an actor to a point in a 3D model.
        \item Dependencies - OpenGL 3.3, GLEW, GLUT, BOOST 1.46, OpenCV.
        \end{enumerate}

        \subsection{Errors and Successes}
        \begin{enumerate}
        \item Very Important : The .vert and .frag Shader files must have the same name before the extension. This took me like 2-3 days to figure out and I did not see it anywhere inside the documentation for OpenGL.
        \item The program will only work on more modern OpenGL version. Go to consol and type 
        \begin{verbatim}glxinfo | grep "OpenGL version" \end{verbatim} 
        to find out which version is currently running on your computer. If it is not 3.3 exactly, this program might not run correctly. It would be useful to fix this but it's too lengthy of a process to concentrate on currently.
        \item The 3D models are not normalized or scaled to proper real world scale. So 0.1 distance in the model might be 3 or 4 foot change in real life. So the program needs to have the \texttt{scale} variable adjusting according to each new model that the user tries to use.
        \item 
        \end{enumerate}

        \subsection{Files}

        



%==== Section 3, Database Generator === %
\section{Database Generator}
\begin{enumerate}
    \item Purpose - Creates a directory full of feature data to accompany each photo created by the Perspective Generator. 
    \item Features include:
    \begin{enumerate}
        \item Average Pixel Sum Image: Take original image, split into divisions, then for each grid square, take the average pixel intensity. This grayscale image is small, around 50x50.
        \item Above Below Image: Take the average intensity of the Average Pixel Sum Image. If a pixel in that image is lighter, make it white. If it's darker, make it black. This image is the same size as the Pixel Sum Image but is binary.
        \item Feature Descriptors: SURF and SIFT descriptors for extracted keypoints in each image.
    \end{enumerate}
    \item Issues:
    \begin{enumerate}
        \item Needs some way to better filter keypoints.
        \item Needs to accept more diverse features.
    \end{enumerate}
\end{enumerate}

  

  




\end{document}