<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>3DLocalization by jhallard</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/jhallard/3DLocalization">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/jhallard/3DLocalization/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/jhallard/3DLocalization/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>3DLocalization</h1>
          <p>Actor (aka robotic) localization via particle filtering, image features, and 3D models.</p>
          <hr>
          <span class="credits left">Created by <a href="https://github.com/jhallard">John Allard</a> and <a href="https://github.com/aarich">Alex Rich</a></span>
          <span class="credits right"> <a href="https://www.cs.hmc.edu/twiki/bin/view/Robotics/SummerStartPage2014"> 
              2014 Harvey Mudd College CS REU</a> </span>
        </div>

        <h2><a name="project-overview" class="anchor" href="#project-overview"><span class="octicon octicon-link"></span></a>Project Overview</h2>
        <p> This project is an small collection of programs that allow a general actor (most of the time a robot) to localize itself in a pre-mapped environment using image-based feature data and particle filtering via the <a href="https://en.wikipedia.org/wiki/Monte_Carlo_localization">Monte Carlo Localization algorithm</a>. This program requires a high-detail, 3 dimensional map of the environment to be obtained or generated by the user before localization can take place. The actor that the user wishes to localize must implement a small interface that requires it to do two things.
        <ol> 
          <li> Publish image data from a camera on the robot. </li>
          <li> Recieve movement commands from our program.</li>
        </ol>
        The rest of the robots functionality is up to the user to decide. Any actor (quadcopters, Roombas, humans, etc.) that can do these two things should be able to localize itself, given a 3D map of its environment.
        As was stated earlier, this project consists of a few programs. These programs are broken up into two main categories.</p>
        <p>
        
        <ol>
        <li> Pre-Localization 
          <ol>
          <li> PerspectiveGenerator - Takes a 3D model and processes it into a library of images.</li>
          <li>DatabaseGenerator - Creates a database of feature data related to the images.</li>
          </ol></li>
          <li>During Localization
          <ol>
          <li>3DLocalization - Uses the data generated in the two Pre-Localization programs to actively locate an actor.</li>
          </ol>
        </li>
        </ol>

        We decided to pre-compute the majority of the 3D-model analysis and image feature detection because of the computational heaviness of these operations. Precomputing features from a dense but finite number of perspectives within a 3D space allows us to speed up the overall process of localizing an actor in an environment by a significant amount.
        </p>

        <h2><a name="official-documentation" class="anchor" href="#official=documentation"><span class="octicon octicon-link"></span></a>Official Documentation</h2>
        <p> This page merely presents a high-level view of this project. For more in-depth documentation, see the following links.
          <u1>  
            <li> Official Code Documentation <a href="https://github.com/jhallard/3DLocalization/tree/master/Documentation/CodeDocumentation"> (LaTeX and PDF).</a> </li>
            <li> Team Research Paper 
              <a href="https://github.com/jhallard/3DLocalization/tree/master/Documentation/ResearchPaper"> (LaTeX and PDF).</a> 
            </li>
            <li> User Manual<a href="https://github.com/jhallard/3DLocalization/tree/master/Documentation/User Manual"> (LaTeX and PDF).</a </li>
          <u1>
        </p>

        <h2> <a name="motivation" class="anchor" href="#motivation"><span class="octicon octicon-link"></span></a>Motivation</h2>
        <p> The motivation for this project came from the previous successes 
          [<a href="http://robots.stanford.edu/papers/fox.aaai99.pdf">1,</a>
          <a href="http://www.sciencedirect.com/science/article/pii/S0004370201000698"> 2</a>]
           of other research teams at localizing a robot in a space using 2D maps of the environment and range data from sensors on the robot. The range data and 2 dimensional map of the environment allowed these teams to implement particle filtering via the 
          <a href="https://en.wikipedia.org/wiki/Monte_Carlo_localization">Monte Carlo Localization algorithm</a>.</p>
        <p> </p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>